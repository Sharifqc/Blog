{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, I will be looking at one of the several choices for neural network modeling in the .NET ecosystem, the Accord machine learning framework, which can be found here:\n",
    "\n",
    "http://accord-framework.net/\n",
    "\n",
    "The Auto MPG dataset from the UCI Machine Learning repository will be used for modeling, which can be found here:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Auto+MPG\n",
    "\n",
    "The following code will load some Accord .NET modules. Accord contains a variety of signal processing and machine learning algorithms for the .NET environment. In this notebook, I will be using the Accord.MachineLearning and Accord.Neuro namespaces, so be sure to copy all required dlls to the working directory of your Jupyter notebook. (For more information about how to load these packages into a Jupyter notebook, refer to the previous blog post):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#r \"Accord.Neuro.dll\"\n",
    "#r \"Accord.MachineLearning.dll\"\n",
    "open System\n",
    "open System.IO\n",
    "open Accord.MachineLearning\n",
    "open Accord.Neuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't worked with F# before, the syntax can be hard to understand at first. I strongly recommend \"FSharp for Fun and Profit\" (http://fsharpforfunandprofit.com/) to pick up the basics.\n",
    "\n",
    "The following code will load the data from the auto mpg CSV file. Before this step, I did some basic data cleaning on the file, which included converting the .data extension to .csv, removing all rows that had missing \"horsepower\" data, removing the last column, and splitting the dataset into an X data file (\"autox.csv\") and a Y data file (\"autoy.csv\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// This code will read all data from the file, skip the header row, and \n",
    "// split each row using a comma separator into 6 columns.\n",
    "let xdata = File.ReadAllLines(\"C:\\\\Users\\\\ERIC\\\\Desktop\\\\Auto MPG\\\\autox.csv\")\n",
    "                |> Array.toSeq\n",
    "                |> Seq.skip 1\n",
    "                |> Seq.toArray\n",
    "                |> Array.map ( fun t -> t.Split(',') \n",
    "                                        |> Array.map(fun t -> double t ))\n",
    "// This code will read all data from the file, skip the header row, and \n",
    "// split each row using a comma separator into 1 column.\n",
    "let ydata = File.ReadAllLines(\"C:\\\\Users\\\\ERIC\\\\Desktop\\\\Auto MPG\\\\autoy.csv\")\n",
    "                |> Array.toSeq\n",
    "                |> Seq.skip 1\n",
    "                |> Seq.toArray\n",
    "                |> Array.map ( fun t -> t.Split(',') \n",
    "                                        |> Array.map(fun t -> double t ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll divide the data into a training and testing dataset, necessary for cross validation. Accord.NET has a \"SplitSetValidation\" class to easily accomplish this. The first parameter of \"SplitSetValidation\" is the size of the input matrix, and the second parameter is the proportion of data to use for training. I use the \"TrainingSet\" and \"ValidationSet\" indices from the \"SplitSetValidation\" to grab a subset of rows from the original array.\n",
    "\n",
    "The \"X\" values used to predict \"MPG\" (Column 0) will be the \"Cylinder\", \"Displacement\", \"Horsepower\", \"Weight\", \"Accleration\", and \"Year\" columns (1 through 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Divide the data into testing and training datasets\n",
    "let split = SplitSetValidation(xdata.Length, 0.7)\n",
    "let XTrain = [| for i in split.TrainingSet -> xdata.[i]|]\n",
    "let yTrain = [| for i in split.TrainingSet -> ydata.[i]|]\n",
    "let XTest = [| for i in split.ValidationSet -> xdata.[i]|]\n",
    "let yTest = [| for i in split.ValidationSet -> ydata.[i]|]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will construct a very simple neural network with a sigmoid activation function, using two hidden layers with 10 nodes each. The learning algorithm will be the Levenberg-Marquardt method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// This function initializes a new neural network by the number of \n",
    "// inputs and the neurons in each hidden layer. neurons is an array\n",
    "// of nodes in each hidden layer. For example, [| 5; 10 |] means 5\n",
    "// nodes in the first layer and 10 in the second layer.\n",
    "let createNetwork (numInputs: int) (neurons: int[]) =   \n",
    "    let act = SigmoidFunction()\n",
    "    let network = ActivationNetwork(act, numInputs, neurons)\n",
    "    Learning.LevenbergMarquardtLearning network \n",
    "    \n",
    "// As an example, this code will initialize a neural network with two hidden \n",
    "// layers, with 10 nodes each. Important note- the neurons need to be an \n",
    "// array, not a list. Create an array using [| X; Y |] notation.\n",
    "let nn1 = createNetwork 2 [| 10; 1 |]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next, we will construct a function to run the neural network called \"runNetwork\". To make the function a little easier to use, I'm just going to call the \"createNetwork\" function inside the \"runNetwork\" function. This will save lines of code when running a loop of many different neural network architectures.\n",
    "\n",
    "Inside the function, I have created a very simple stopping criteria. Defining stopping criteria within a neural network allows the network to stop execution early if certain modeling conditions have been reached (for example, a low training error). The learning method employed here is stochastic; depending on the random initial conditions and the local minima encountered in the error space, the network will likely achieve different results each time it is run. To keep the end goal in focus, what we're really interested in is the error on the testing data, not the training data. The following code will detect if a neural network is \"stuck\" in a local minima; if so, we want to stop execution and check the testing error. If it's good enough, we're done. If not, we may need to adjust the learning rate so that it does not get stuck in local minima as easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.011253676"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// This function will train the neural network until the stopping\n",
    "// criteria is reached. It calls the createNetwork function above.\n",
    "let runNetwork (neurons: int[]) (inputs: double[][]) (output: double[][]) (num_inp: int) =\n",
    "    let nn = createNetwork num_inp neurons\n",
    "    // Given that ANNs are stochastic, there is not really a way to get\n",
    "    // around the use of \"mutable\" here, at least that I see.\n",
    "    let mutable previous = 2.0\n",
    "    let mutable error = 1.0\n",
    "    let mutable check = true\n",
    "    let mutable epoch = 0\n",
    "    while check do\n",
    "        error <- nn.RunEpoch(inputs, output)\n",
    "        // The error returned above is the sum of squared errors- let's make it the mean error\n",
    "        error <- Math.Sqrt(error) / (float inputs.Length)\n",
    "        // The stopping criteria is that the error must change by at least 0.00001 each epoch, \n",
    "        // the error must be less than 1.2, and # of epochs must be less than 100000\n",
    "        check <- ((Math.Abs(previous - error) > 0.00001) || (error > 1.2)) && (epoch < 100000)\n",
    "        previous <- error\n",
    "        epoch <- epoch + 1\n",
    "    nn\n",
    "\n",
    "// Run the neural network\n",
    "let nn = runNetwork [| 10; 1 |] XTrain yTrain 6\n",
    "let error = nn.RunEpoch(XTest, yTest)\n",
    "let test_error = Math.Sqrt(error) / (float XTest.Length)\n",
    "test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Based on the testing error, we were able to predict the MPG with a mean absolute error of 1.011, which is fairly good.\n",
    "\n",
    "Alternatively, the data could have been loaded using Deedle, which is a data cleaning and preprocessing library similar to pandas in Python. The following code demonstrates how this would have been done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#r \"Deedle.dll\"\n",
    "open Deedle\n",
    "\n",
    "// Load the data from the CSV file\n",
    "let df = Frame.ReadCsv \"auto-mpg.csv\" |> Frame.dropSparseRows\n",
    "// Examine the column names\n",
    "df.Columns.Keys\n",
    "// Specify the X and Y columns to keep\n",
    "let xcols = [ \"Cylinder\"; \"Displacement\"; \"Weight\"; \"Acceleration\"; \"Year\" ]\n",
    "let ycols = [\"MPG\"]\n",
    "\n",
    "// Divide the data into testing and training datasets\n",
    "let split = SplitSetValidation(392, 0.7)\n",
    "let train = df.Rows.[split.TrainingSet]\n",
    "let test = df.Rows.[split.ValidationSet]\n",
    "let XTrain = train.Columns.[xcols] |> Frame.toArray2D\n",
    "let yTrain = train.Columns.[ycols] |> Frame.toArray2D\n",
    "let XTest = test.Columns.[xcols] |> Frame.toArray2D\n",
    "let yTest = test.Columns.[ycols] |> Frame.toArray2D"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "F#",
   "language": "fsharp",
   "name": "ifsharp"
  },
  "language": "fsharp",
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".fs",
   "mimetype": "text/x-fsharp",
   "name": "fsharp",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "4.3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
